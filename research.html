---
layout: page
title: Research
show_title: true
permalink: /research/
tags: research
---


<style>
  .link {
  color: black;
  }
  .link:hover {
      color: #A0D4A4;
      text-decoration: none;
  }
}
</style>




<div>
  <table>
    <tr>
    </tr>
  </table>
</div>

<p>
  We enable intelligent robots to collaborate with people (<a href=\"https://news.vt.edu/videos/k/2023/11/1_nd818p5k.html">video link</a>).
</p>

<center>
  <iframe  width="100%" height="500px" src="https://www.youtube.com/embed/P7IaDuJLUCo" frameborder="0" allowfullscreen></iframe>
</center>
<br>


<p>
Our group explores the foundations of human-robot interaction.
Our goal is to enable robots to seamlessly and intelligently interact with human partners.
We seek out problems inspired by the challenges of everyday users &mdash;
particularly for assistive robot arms and self-driving cars &mdash;
as well as problems motivated by future applications &mdash; such as personal robots or robots in the home.
Our projects typically involve three steps:
<ol>
  <li>Formalizing the problem within a larger context</li>
  <li>Creating a learning or control based solution</li>
  <li>Testing our approach with real people and robots</li>
</ol>
We believe that effective research balances theory and practice.
We strive to fundamentally understand how humans and robot should interact,
while also conducting user studies to determine what people really need.
</p>

<h2> Research Directions </h2>

<center>
  <iframe  width="100%" height="500px" src="https://www.youtube.com/embed/n79FxkA_im0" frameborder="0" allowfullscreen></iframe>
</center>
<br>

Collab is currently focused on two problems:
(1) how should robots learn from humans and
(2) how can robots communicate their learning back to human teachers.

<h2> Learning from Humans </h2>

<img src="{{ site.baseurl }} /images/research/inclusive.gif" style="width:100%; height:100%;" class="center">
<br>

<p>
  When people interact with robots, often they want to teach their robot a new skill
  or control their robot to perform a different task.
  For example, in the video above a user is controlling an assistive robot arm.
  Instead of asking for human guidance at every step of the process,
  we envision robots that infer what the human wants and autonomously help
  to complete that task.
  We are excited about creating interactive learning and control strategies that
  (a) rapidly adapt to the current user,
  (b) provide performance and safety guarantees,
  and (c) work well across different users, tasks, and environments.
</p>

<h2> Communicating with Humans </h2>

<img src="{{ site.baseurl }} /images/research/explainable.gif" style="width:100%; height:100%;" class="center">
<br>

<p>
  Learning is a key component of robotics.
  In order for robots to solve everyday tasks,
  they must be able to learn from the humans around them.
  But from the human's perspective this learning is a black box:
  in the video above, how does the person know whether their robot arm
  has learned to avoid the green cup?
  We envision robots that actively and intuitively reveal their learning to human operators.
  We are excited about solutions that bridge both physical and algorithmic intelligence
  to seamlessly bring nearby users into the robot's learning loop.
  This includes a single human working with a single robot,
  or teams of humans working with multiple robots.
</p>
